{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attention-based ODIR Classifier: EfficientNet + Transformer Head\n",
        "\n",
        "This notebook trains an attention-augmented image classifier for ODIR using an EfficientNet backbone and a lightweight Transformer encoder over spatial tokens.\n",
        "\n",
        "- Backbone: EfficientNetB0 (switchable to B3)\n",
        "- Head: Transformer encoder with multi-head self-attention\n",
        "- Metrics: accuracy, weighted F1, ROC-AUC, PR-AUC\n",
        "- Saves: best model, history, confusion matrices, classification report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Augmentations and EfficientNet preprocessing (self-contained imports)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as effnet_preprocess\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "], name=\"augment\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "try:\n",
        "    import tensorflow_addons as tfa\n",
        "    USE_TFA = True\n",
        "except Exception:\n",
        "    tfa = None\n",
        "    USE_TFA = False\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB3\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Kaggle input directory (ODIR-5K structure)\n",
        "DATA_DIR = \"/kaggle/input/ocular-disease-recognition-odir5k\"\n",
        "OUTPUT_DIR = \"/kaggle/working\"\n",
        "\n",
        "IMAGE_SIZE = 224\n",
        "BACKBONE = \"b0\"  # \"b0\" or \"b3\"\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 40\n",
        "SEED = 42\n",
        "RUN_TRANSFORMER = False  # guard to skip transformer training to save memory\n",
        "\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "\n",
        "# Enable mixed precision to reduce memory\n",
        "try:\n",
        "    from tensorflow.keras import mixed_precision\n",
        "    mixed_precision.set_global_policy('mixed_float16')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Disable XLA JIT to reduce GPU timer warnings on some Kaggle GPUs\n",
        "try:\n",
        "    tf.config.optimizer.set_jit(False)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "NUM_WORKERS = 2\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Robust stratified split ensuring each class appears in val/test\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "def stratified_split_with_min(df, label_col=\"label\", val_size=0.15, test_size=0.15, seed=SEED, attempts=100):\n",
        "    sss1 = StratifiedShuffleSplit(n_splits=attempts, test_size=val_size+test_size, random_state=seed)\n",
        "    labels = df[label_col].values\n",
        "    for train_idx, temp_idx in sss1.split(df, labels):\n",
        "        train_df_cand = df.iloc[train_idx]\n",
        "        temp_df_cand = df.iloc[temp_idx]\n",
        "        sss2 = StratifiedShuffleSplit(n_splits=1, test_size=test_size/(val_size+test_size), random_state=seed)\n",
        "        for val_idx, test_idx in sss2.split(temp_df_cand, temp_df_cand[label_col].values):\n",
        "            val_df_cand = temp_df_cand.iloc[val_idx]\n",
        "            test_df_cand = temp_df_cand.iloc[test_idx]\n",
        "            if set(val_df_cand[label_col].unique()) == set(TARGET) and set(test_df_cand[label_col].unique()) == set(TARGET):\n",
        "                return train_df_cand.reset_index(drop=True), val_df_cand.reset_index(drop=True), test_df_cand.reset_index(drop=True)\n",
        "    print(\"Warning: could not guarantee all classes in val/test; using best-effort stratified split.\")\n",
        "    return train_df_cand.reset_index(drop=True), val_df_cand.reset_index(drop=True), test_df_cand.reset_index(drop=True)\n",
        "\n",
        "# Override previous split with robust one\n",
        "train_df, val_df, test_df = stratified_split_with_min(df, label_col=\"label\", val_size=0.15, test_size=0.15, seed=SEED)\n",
        "print(\"Counts:\", len(train_df), len(val_df), len(test_df))\n",
        "print(\"Val class counts:\\n\", val_df[\"label\"].value_counts())\n",
        "print(\"Test class counts:\\n\", test_df[\"label\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build dataset from ODIR-5K file structure\n",
        "# We will use single-label subset for 5-class case: G, C, A, H, M\n",
        "\n",
        "import re\n",
        "\n",
        "ODIR_DIR = os.path.join(DATA_DIR, \"ODIR-5K\", \"ODIR-5K\")\n",
        "EXCEL_PATH = os.path.join(ODIR_DIR, \"data.xlsx\")\n",
        "TRAIN_IMG_DIR = os.path.join(ODIR_DIR, \"Training Images\")\n",
        "TEST_IMG_DIR = os.path.join(ODIR_DIR, \"Testing Images\")\n",
        "\n",
        "assert os.path.exists(EXCEL_PATH), \"data.xlsx not found at expected path\"\n",
        "\n",
        "# Read metadata\n",
        "meta = pd.read_excel(EXCEL_PATH)\n",
        "\n",
        "# Helper: find column containing all substrings (case-insensitive)\n",
        "def find_col(df, substrings):\n",
        "    subs = [s.lower() for s in substrings]\n",
        "    for c in df.columns:\n",
        "        lc = str(c).lower()\n",
        "        if all(s in lc for s in subs):\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "left_img_col = find_col(meta, [\"left\", \"fundus\"]) or find_col(meta, [\"left\", \"image\"])\n",
        "right_img_col = find_col(meta, [\"right\", \"fundus\"]) or find_col(meta, [\"right\", \"image\"])\n",
        "left_diag_col = find_col(meta, [\"left\", \"diagn\"]) or find_col(meta, [\"left\", \"keyword\"])\n",
        "right_diag_col = find_col(meta, [\"right\", \"diagn\"]) or find_col(meta, [\"right\", \"keyword\"])\n",
        "\n",
        "assert left_img_col and right_img_col, \"Could not locate Left/Right Fundus columns in data.xlsx\"\n",
        "\n",
        "# Map diagnosis text to short labels\n",
        "KEYWORD_TO_SHORT = {\n",
        "    \"glaucoma\": \"G\",\n",
        "    \"cataract\": \"C\",\n",
        "    \"amd\": \"A\",\n",
        "    \"age-related macular degeneration\": \"A\",\n",
        "    \"age related macular degeneration\": \"A\",\n",
        "    \"hypertension\": \"H\",\n",
        "    \"myopia\": \"M\",\n",
        "    \"normal\": \"N\",\n",
        "    \"diabetic retinopathy\": \"D\",\n",
        "    \"dr\": \"D\",\n",
        "    \"other\": \"O\",\n",
        "    \"others\": \"O\",\n",
        "}\n",
        "\n",
        "def text_to_labels(text):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    text_l = text.lower()\n",
        "    labels = set()\n",
        "    # keyword search\n",
        "    for k, s in KEYWORD_TO_SHORT.items():\n",
        "        if k in text_l:\n",
        "            labels.add(s)\n",
        "    # bracket short labels like ['G'] fallback\n",
        "    labels.update(re.findall(r\"[DGCAHMNO]\", text))\n",
        "    return sorted(labels)\n",
        "\n",
        "# Build records\n",
        "records = []\n",
        "for _, row in meta.iterrows():\n",
        "    for side, img_col, diag_col in [\n",
        "        (\"L\", left_img_col, left_diag_col),\n",
        "        (\"R\", right_img_col, right_diag_col),\n",
        "    ]:\n",
        "        fname = row.get(img_col)\n",
        "        if isinstance(fname, str) and len(fname) > 0:\n",
        "            diag_text = row.get(diag_col) if diag_col in meta.columns else None\n",
        "            short_labels = text_to_labels(diag_text)\n",
        "            if len(short_labels) == 0:\n",
        "                continue\n",
        "            records.append({\n",
        "                \"filename\": fname,\n",
        "                \"labels\": short_labels,\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame.from_records(records)\n",
        "\n",
        "# Keep only single-label images from target 5 classes\n",
        "TARGET = [\"G\",\"C\",\"A\",\"H\",\"M\"]\n",
        "if len(df) == 0:\n",
        "    raise RuntimeError(\"No labeled images parsed from data.xlsx; please verify column names in your ODIR file.\")\n",
        "\n",
        "df[\"labels\"] = df[\"labels\"].apply(lambda lst: [l for l in lst if l in TARGET])\n",
        "df = df[df[\"labels\"].apply(len) == 1].copy()\n",
        "df[\"label\"] = df[\"labels\"].apply(lambda lst: lst[0])\n",
        "\n",
        "class_to_idx = {c:i for i,c in enumerate(TARGET)}\n",
        "num_classes = len(TARGET)\n",
        "\n",
        "# Resolve file path: prefer Training, else Testing\n",
        "paths = []\n",
        "for fname in df[\"filename\"].values:\n",
        "    p = os.path.join(TRAIN_IMG_DIR, fname)\n",
        "    if not os.path.exists(p):\n",
        "        p = os.path.join(TEST_IMG_DIR, fname)\n",
        "    paths.append(p)\n",
        "df[\"path\"] = paths\n",
        "\n",
        "# Filter only existing files\n",
        "df = df[df[\"path\"].apply(os.path.exists)].reset_index(drop=True)\n",
        "\n",
        "print(\"Samples per class:\")\n",
        "print(df[\"label\"].value_counts())\n",
        "\n",
        "# Train/val/test split stratified\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=SEED, stratify=df[\"label\"]) \n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, stratify=temp_df[\"label\"]) \n",
        "\n",
        "print(\"Counts:\", len(train_df), len(val_df), len(test_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image loader\n",
        "def load_and_preprocess(path, image_size=IMAGE_SIZE):\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        # create a black image placeholder if missing\n",
        "        img = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (image_size, image_size))\n",
        "    # Keep in [0,255] float; EfficientNet preprocess handles scaling\n",
        "    img = img.astype(\"float32\")\n",
        "    return img\n",
        "\n",
        "# Build numpy arrays (simple and memory-friendly for Kaggle scales)\n",
        "\n",
        "def df_to_arrays(df):\n",
        "    xs = np.stack([load_and_preprocess(p) for p in df[\"path\"].values], axis=0)\n",
        "    ys = np.array([class_to_idx[c] for c in df[\"label\"].values])\n",
        "    ys = tf.keras.utils.to_categorical(ys, num_classes=num_classes)\n",
        "    return xs, ys\n",
        "\n",
        "x_train, y_train = df_to_arrays(train_df)\n",
        "x_val, y_val = df_to_arrays(val_df)\n",
        "x_test, y_test = df_to_arrays(test_df)\n",
        "\n",
        "print(\"Array shapes:\")\n",
        "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optionally override with pre-saved numpy arrays if present in this Kaggle dataset\n",
        "npy_files = [\n",
        "    os.path.join(DATA_DIR, \"x_train.npy\"),\n",
        "    os.path.join(DATA_DIR, \"y_train.npy\"),\n",
        "    os.path.join(DATA_DIR, \"x_val.npy\"),\n",
        "    os.path.join(DATA_DIR, \"y_val.npy\"),\n",
        "    os.path.join(DATA_DIR, \"x_test.npy\"),\n",
        "    os.path.join(DATA_DIR, \"y_test.npy\"),\n",
        "]\n",
        "\n",
        "if all(os.path.exists(p) for p in npy_files):\n",
        "    x_train = np.load(npy_files[0]).astype(\"float32\") / 255.0\n",
        "    y_train = np.load(npy_files[1])\n",
        "    x_val = np.load(npy_files[2]).astype(\"float32\") / 255.0\n",
        "    y_val = np.load(npy_files[3])\n",
        "    x_test = np.load(npy_files[4]).astype(\"float32\") / 255.0\n",
        "    y_test = np.load(npy_files[5])\n",
        "    num_classes = int(y_train.shape[1])\n",
        "    print(\"Loaded pre-saved numpy arrays from Kaggle dataset.\")\n",
        "    print(\"Shapes:\")\n",
        "    print(\" x_train:\", x_train.shape)\n",
        "    print(\" y_train:\", y_train.shape)\n",
        "    print(\" x_val:\", x_val.shape)\n",
        "    print(\" y_val:\", y_val.shape)\n",
        "    print(\" x_test:\", x_test.shape)\n",
        "    print(\" y_test:\", y_test.shape)\n",
        "else:\n",
        "    print(\"Using arrays built from ODIR file structure.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model_cbam(image_size=224, backbone=\"b0\", num_classes=5, dropout=0.3):\n",
        "    tf.keras.backend.clear_session()\n",
        "    inputs = layers.Input(shape=(image_size, image_size, 3))\n",
        "    x_in = data_augmentation(inputs)\n",
        "    x_in = effnet_preprocess(x_in)\n",
        "    backbone_model = build_backbone(x_in, backbone=backbone, image_size=image_size)\n",
        "    x = backbone_model.output\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = CBAM()(x)\n",
        "    x = layers.Conv2D(192, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Dense(192, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)  # force float32 output under mixed precision\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CBAM attention module for CNN feature maps\n",
        "@tf.keras.utils.register_keras_serializable(package=\"custom\")\n",
        "class CBAM(layers.Layer):\n",
        "    def __init__(self, reduction_ratio: int = 16, kernel_size: int = 7, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        channels = int(input_shape[-1])\n",
        "        hidden = max(channels // self.reduction_ratio, 1)\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            layers.Dense(hidden, activation=\"relu\"),\n",
        "            layers.Dense(channels)\n",
        "        ])\n",
        "        self.spatial_conv = layers.Conv2D(1, kernel_size=self.kernel_size, padding=\"same\", activation=\"sigmoid\")\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        # Channel attention\n",
        "        avg_pool = tf.reduce_mean(x, axis=[1,2], keepdims=True)\n",
        "        max_pool = tf.reduce_max(x, axis=[1,2], keepdims=True)\n",
        "        mlp_avg = self.mlp(layers.Flatten()(avg_pool))\n",
        "        mlp_max = self.mlp(layers.Flatten()(max_pool))\n",
        "        channel_attn = tf.nn.sigmoid(mlp_avg + mlp_max)\n",
        "        channel_attn = tf.reshape(channel_attn, (-1,1,1,tf.shape(x)[-1]))\n",
        "        x = x * channel_attn\n",
        "        # Spatial attention\n",
        "        avg_pool_sp = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
        "        max_pool_sp = tf.reduce_max(x, axis=-1, keepdims=True)\n",
        "        sp = tf.concat([avg_pool_sp, max_pool_sp], axis=-1)\n",
        "        spatial_attn = self.spatial_conv(sp)\n",
        "        x = x * spatial_attn\n",
        "        return x\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        cfg.update({\"reduction_ratio\": self.reduction_ratio, \"kernel_size\": self.kernel_size})\n",
        "        return cfg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_backbone(input_tensor, backbone=\"b0\", image_size=224):\n",
        "    if backbone == \"b3\":\n",
        "        base = EfficientNetB3(include_top=False, weights=\"imagenet\", input_tensor=input_tensor)\n",
        "    else:\n",
        "        base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=input_tensor)\n",
        "    for layer in base.layers:\n",
        "        layer.trainable = True\n",
        "    return base\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"custom\")\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patches: int, projection_dim: int, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patches = num_patches\n",
        "        self.projection_dim = projection_dim\n",
        "        self.pos_emb = self.add_weight(\n",
        "            name=\"pos_emb\", shape=(1, num_patches, projection_dim), initializer=\"random_normal\"\n",
        "        )\n",
        "\n",
        "    def call(self, x):  # x: (batch, num_patches, projection_dim)\n",
        "        return x + self.pos_emb\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"num_patches\": self.num_patches,\n",
        "            \"projection_dim\": self.projection_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"custom\")\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, projection_dim: int, num_heads: int, mlp_dim: int, dropout: float=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.projection_dim = projection_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.mlp_dim = mlp_dim\n",
        "        self.dropout = dropout\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim, dropout=dropout)\n",
        "        self.drop1 = layers.Dropout(dropout)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            layers.Dense(mlp_dim, activation=tf.nn.gelu),\n",
        "            layers.Dropout(dropout),\n",
        "            layers.Dense(projection_dim),\n",
        "            layers.Dropout(dropout),\n",
        "        ])\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        h = self.norm1(x)\n",
        "        h = self.attn(h, h, training=training)\n",
        "        x = x + self.drop1(h, training=training)\n",
        "        h2 = self.norm2(x)\n",
        "        h2 = self.mlp(h2, training=training)\n",
        "        return x + h2\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"projection_dim\": self.projection_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"mlp_dim\": self.mlp_dim,\n",
        "            \"dropout\": self.dropout,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "def build_model(image_size=224, backbone=\"b0\", num_classes=5, transformer_layers=2, projection_dim=256, num_heads=4, mlp_dim=512, dropout=0.2):\n",
        "    inputs = layers.Input(shape=(image_size, image_size, 3))\n",
        "    # CNN backbone\n",
        "    backbone_model = build_backbone(inputs, backbone=backbone, image_size=image_size)\n",
        "    # Feature map: (B, H', W', C')\n",
        "    features = backbone_model.output\n",
        "    features = layers.BatchNormalization()(features)\n",
        "\n",
        "    # Project channel dimension to projection_dim\n",
        "    proj = layers.Conv2D(projection_dim, kernel_size=1, padding=\"same\")(features)\n",
        "    # Flatten spatial to tokens\n",
        "    tokens = layers.Reshape((-1, projection_dim))(proj)  # (B, N, D)\n",
        "\n",
        "    # Positional embedding\n",
        "    num_patches = (proj.shape[1] or (image_size // 7)) * (proj.shape[2] or (image_size // 7))\n",
        "    tokens = PositionalEmbedding(num_patches=num_patches, projection_dim=projection_dim)(tokens)\n",
        "\n",
        "    # Transformer encoder stack\n",
        "    x = tokens\n",
        "    for _ in range(transformer_layers):\n",
        "        x = TransformerEncoder(projection_dim=projection_dim, num_heads=num_heads, mlp_dim=mlp_dim, dropout=dropout)(x)\n",
        "\n",
        "    # Token pooling\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Classification head\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Suppress Keras build warnings by providing trivial build methods\n",
        "\n",
        "def _attach_trivial_build(cls):\n",
        "    if not hasattr(cls, \"build\") or cls.build is layers.Layer.build:\n",
        "        def build(self, input_shape):\n",
        "            self.built = True\n",
        "        cls.build = build\n",
        "\n",
        "_attach_trivial_build(PositionalEmbedding)\n",
        "_attach_trivial_build(TransformerEncoder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build model (switch to CBAM head)\n",
        "model = build_model_cbam(\n",
        "    image_size=IMAGE_SIZE,\n",
        "    backbone=BACKBONE,\n",
        "    num_classes=num_classes,\n",
        "    dropout=0.4,\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# Metrics\n",
        "METRICS = [\n",
        "    tf.keras.metrics.CategoricalAccuracy(name=\"acc\"),\n",
        "    tf.keras.metrics.AUC(name=\"auc\"),\n",
        "    tf.keras.metrics.AUC(name=\"prc\", curve=\"PR\"),\n",
        "]\n",
        "if USE_TFA:\n",
        "    METRICS.append(tfa.metrics.F1Score(num_classes=num_classes, average=\"weighted\", name=\"f1\"))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=METRICS,\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "ckpt_path = os.path.join(OUTPUT_DIR, \"best_attention_efficientnet.keras\")\n",
        "callbacks = [\n",
        "    ModelCheckpoint(ckpt_path, save_best_only=True, monitor=\"val_acc\", mode=\"max\"),\n",
        "    ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6, verbose=1),\n",
        "    EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_acc\", mode=\"max\", verbose=1),\n",
        "]\n",
        "\n",
        "_ = model.predict(x_train[:4], verbose=0)\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "import pickle\n",
        "with open(os.path.join(OUTPUT_DIR, \"attention_history.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(history.history, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optionally build transformer model (memory heavy)\n",
        "if RUN_TRANSFORMER:\n",
        "    model = build_model(\n",
        "        image_size=IMAGE_SIZE,\n",
        "        backbone=BACKBONE,\n",
        "        num_classes=num_classes,\n",
        "        transformer_layers=3,\n",
        "        projection_dim=384 if BACKBONE == \"b3\" else 256,\n",
        "        num_heads=6 if BACKBONE == \"b3\" else 4,\n",
        "        mlp_dim=768 if BACKBONE == \"b3\" else 512,\n",
        "        dropout=0.3,\n",
        "    )\n",
        "    model.summary()\n",
        "\n",
        "# Metrics\n",
        "METRICS = [\n",
        "    tf.keras.metrics.CategoricalAccuracy(name=\"acc\"),\n",
        "    tf.keras.metrics.AUC(name=\"auc\"),\n",
        "    tf.keras.metrics.AUC(name=\"prc\", curve=\"PR\"),\n",
        "]\n",
        "if USE_TFA:\n",
        "    METRICS.append(tfa.metrics.F1Score(num_classes=num_classes, average=\"weighted\", name=\"f1\"))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=METRICS,\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "ckpt_path = os.path.join(OUTPUT_DIR, \"best_attention_efficientnet.keras\")\n",
        "callbacks = [\n",
        "    ModelCheckpoint(ckpt_path, save_best_only=True, monitor=\"val_acc\", mode=\"max\"),\n",
        "    ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6, verbose=1),\n",
        "    EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_acc\", mode=\"max\", verbose=1),\n",
        "]\n",
        "\n",
        "# Warm-up forward pass to stabilize cuDNN timers\n",
        "_ = model.predict(x_train[:4], verbose=0)\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Save history\n",
        "import pickle\n",
        "with open(os.path.join(OUTPUT_DIR, \"attention_history.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(history.history, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Load best model\n",
        "custom_objects = {\"PositionalEmbedding\": PositionalEmbedding, \"TransformerEncoder\": TransformerEncoder}\n",
        "best_model = tf.keras.models.load_model(ckpt_path, custom_objects=custom_objects, compile=False)\n",
        "best_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=METRICS)\n",
        "\n",
        "# Evaluate\n",
        "eval_results = best_model.evaluate(x_test, y_test, verbose=0)\n",
        "print({m.name: v for m, v in zip(best_model.metrics, eval_results[1:])})\n",
        "\n",
        "# Predictions\n",
        "y_prob = best_model.predict(x_test, batch_size=BATCH_SIZE, verbose=0)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Confusion matrix with full class names and normalized percentages\n",
        "labels = list(range(num_classes))\n",
        "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
        "class_names_full = [\"Glaucoma\",\"Cataract\",\"AMD\",\"Hypertension\",\"Myopia\"] if num_classes == 5 else [f\"Class_{i}\" for i in labels]\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.heatmap(cm_norm*100, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names_full, yticklabels=class_names_full)\n",
        "plt.title('Confusion Matrix (Test)')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix_test.png'))\n",
        "plt.show()\n",
        "\n",
        "# Classification report with fixed label set\n",
        "report = classification_report(y_true, y_pred, labels=labels, target_names=class_names_full, zero_division=0)\n",
        "print(report)\n",
        "with open(os.path.join(OUTPUT_DIR, 'classification_report.txt'), 'w') as f:\n",
        "    f.write(report)\n",
        "\n",
        "# ROC-AUC and PR-AUC restricted to present classes\n",
        "present = sorted(list(set(y_true)))\n",
        "try:\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "    y_true_bin = tf.keras.utils.to_categorical(y_true, num_classes=num_classes)\n",
        "    roc_auc = roc_auc_score(y_true_bin[:,present], y_prob[:,present], average='macro', multi_class='ovr')\n",
        "    pr_auc = average_precision_score(y_true_bin[:,present], y_prob[:,present], average='macro')\n",
        "    print('ROC-AUC (macro, OvR):', round(roc_auc, 4))\n",
        "    print('PR-AUC (macro):', round(pr_auc, 4))\n",
        "except Exception as e:\n",
        "    print('ROC/PR AUC could not be computed:', e)\n",
        "\n",
        "# Plot training curves\n",
        "hist = history.history\n",
        "for key_pair in [(\"acc\",\"val_acc\"),(\"auc\",\"val_auc\"),(\"prc\",\"val_prc\"),(\"loss\",\"val_loss\")]:\n",
        "    tr, va = key_pair\n",
        "    if tr in hist and va in hist:\n",
        "        plt.figure()\n",
        "        plt.plot(hist[tr], label=tr)\n",
        "        plt.plot(hist[va], label=va)\n",
        "        plt.title(tr + ' vs ' + va)\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, f'{tr}_curve.png'))\n",
        "        plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
